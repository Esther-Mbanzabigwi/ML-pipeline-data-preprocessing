{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37BV7-CMEbMj"
      },
      "source": [
        "# Data Processing Approach for Portfolio Project\n",
        "--------------------------------------------------------------------------------\n",
        "## **Project Title**:  **Lung Segmentation of Normal, Viral Pneumonia, and COVID-affected Lungs**\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "## **Student Name**: **Esther MBANZABIGWI**\n",
        "\n",
        "---\n",
        "1.Data Sources and Aggregation\n",
        "\n",
        "Data Sources:\n",
        "\n",
        "The primary dataset for this project is the COVID-19 Radiography Dataset, which is publicly available. Additional sources can include:\n",
        "\n",
        ".Peer-reviewed articles that provide annotated radiography datasets.\n",
        "\n",
        ".Open medical imaging repositories like MedPix and The Cancer Imaging Archive.\n",
        "\n",
        ".Research papers detailing pneumonia cases and lung scans.\n",
        "\n",
        "\n",
        "Data Aggregation:\n",
        "\n",
        "Aggregating data from multiple sources ensures comprehensive modeling and analysis. For instance, combining COVID-19 radiographs with general pneumonia and healthy lung datasets improves model robustness.\n",
        "\n"
      ],
      "id": "37BV7-CMEbMj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "2. **Data Format Transformation:**\n",
        "   Current Data Format:\n",
        "The dataset consists of images stored in .png format, organized by folder labels for each category (Normal, Pneumonia, and COVID).\n",
        "\n",
        "Planned Transformation:\n",
        "Images will be resized (e.g., 224x224) to ensure uniformity across training. File paths will be mapped to corresponding labels in a structured format (e.g., CSV or Pandas DataFrame).\n",
        "\n",
        "3. **Data Exploration:**\n",
        "   \n",
        "Features:\n",
        "\n",
        "Input Features: Pixel intensities of radiograph images.\n",
        "\n",
        "Target Feature: Class labels (Normal, Pneumonia, COVID).\n",
        "\n",
        "Exploratory Data Analysis (EDA):\n",
        "Analyzing image histograms to understand brightness and contrast distributions. Heatmaps to identify correlations among pixel values."
      ],
      "metadata": {
        "id": "TzyeghJDEjit"
      },
      "id": "TzyeghJDEjit"
    },
    {
      "cell_type": "code",
      "source": [
        "#Include plots for EDA\n",
        "#Include plots for EDA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Load a sample image for EDA\n",
        "sample_image_path = 'path_to_sample_image.png'\n",
        "# Replace 'path_to_sample_image.png' with the actual path to your image\n",
        "sample_image = cv2.imread(sample_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if sample_image is None:\n",
        "    print(f\"Error: Could not load image from {sample_image_path}. Please check the file path and ensure the image exists.\")\n",
        "else:\n",
        "    # Display the image histogram\n",
        "    plt.hist(sample_image.ravel(), bins=256, color='blue')\n",
        "    plt.title('Pixel Intensity Distribution')\n",
        "    plt.xlabel('Pixel Intensity')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oYEgIOxSFUHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9261ddad-d5cf-4e79-e96d-9ef7c17dbe5f"
      },
      "id": "oYEgIOxSFUHW",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not load image from path_to_sample_image.png. Please check the file path and ensure the image exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "4. **Hypothesis Testing:**\n",
        "   \n",
        "  \n",
        "\n",
        "Hypotheses:\n",
        "\n",
        "COVID-affected lungs exhibit unique radiographic patterns compared to normal and pneumonia-affected lungs.\n",
        "Augmented datasets improve model performance by mitigating overfitting.\n",
        "\n",
        "Methodology:\n",
        "\n",
        "Test the model's ability to distinguish lung categories based on image patterns using classification metrics like accuracy and recall.\n",
        "\n",
        "5. **Handling Sparse/Dense Data and Outliers:**\n",
        "   \n",
        "\n",
        "Density Assessment:\n",
        "Sparse data in underrepresented categories (e.g., COVID scans).\n",
        "\n",
        "Strategies:\n",
        "\n",
        "Data augmentation (e.g., rotation, flipping).\n",
        "Outlier detection using visual analysis and pixel intensity thresholds.\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "tHKtxjFKFNpB"
      },
      "id": "tHKtxjFKFNpB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting and removing outlier images with extreme pixel intensities\n",
        "import numpy as np\n",
        "\n",
        "def detect_outliers(image_array):\n",
        "    mean_intensity = np.mean(image_array)\n",
        "    if mean_intensity < 10 or mean_intensity > 245:  # Thresholds for outliers\n",
        "        return True\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "f_R52s5RE_wj"
      },
      "id": "f_R52s5RE_wj",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Data Splitting:**\n",
        "   \n",
        "Methodology:\n",
        "Use an 80-10-10 split for training, validation, and testing datasets. Employ stratified sampling to preserve label proportions.\n",
        "\n",
        "7. **Bias Mitigation:**\n",
        "  \n",
        "Techniques:\n",
        "\n",
        "Oversample minority classes using SMOTE for tabular data or image augmentation for image data.\n",
        "\n",
        "Ensure equitable distribution of radiographs by demographics.\n",
        "\n",
        "   \n",
        "    **Your answer for Hypothesis Testing goes here **\n",
        "\n"
      ],
      "metadata": {
        "id": "5SS3lD0sGPGe"
      },
      "id": "5SS3lD0sGPGe"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your data is in a CSV file named 'your_data.csv'\n",
        "# Replace 'your_data.csv' with the actual file path\n",
        "data = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Now you can use 'data' in train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2, stratify=data['labels'])\n",
        "val, test = train_test_split(test, test_size=0.5, stratify=test['labels'])"
      ],
      "metadata": {
        "id": "iX_5Hl65GEgY"
      },
      "id": "iX_5Hl65GEgY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Features for Model Training:**\n",
        "   \n",
        "   Relevant Features:\n",
        "\n",
        "Pixel intensity values.\n",
        "\n",
        "Augmented image variations (rotated, flipped, etc.).\n",
        "\n",
        "Ranking Features:\n",
        "Use feature importance analysis via trained CNN model visualizations.\n",
        "\n",
        "9. **Types of Data Handling:**\n",
        "\n",
        "Data Types:\n",
        "\n",
        "Numerical: Pixel intensities.\n",
        "\n",
        "Categorical: Class labels.\n",
        "\n",
        "Preprocessing:\n",
        "\n",
        "Normalize pixel intensities (0-1 scaling) and encode labels numerically.\n",
        "\n",
        "\n",
        "\n",
        "   \n"
      ],
      "metadata": {
        "id": "OzGrkCCXGUxV"
      },
      "id": "OzGrkCCXGUxV"
    },
    {
      "cell_type": "code",
      "source": [
        "#print out relevant features"
      ],
      "metadata": {
        "id": "YNkqADAQGbNZ"
      },
      "id": "YNkqADAQGbNZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "10. **Data Transformation for Modeling:**\n",
        "\n",
        "Methods:\n",
        "\n",
        "Normalization of pixel values.\n",
        "\n",
        "Encoding categorical labels.\n",
        "\n",
        "11. **Data Storage:**\n",
        "\n",
        "Storage Solution:\n",
        "\n",
        "Processed data stored in an AWS S3 bucket with access controls or a local directory structured for reproducibility.\n",
        "---\n",
        "\n",
        "#### Notes:\n",
        "- This template provides a structured framework for documenting your data processing approach for the portfolio project.\n",
        "- Fill out each section with specific details relevant to your project's requirements and objectives.\n",
        "- Use additional cells as needed to provide comprehensive information."
      ],
      "metadata": {
        "id": "lG_mx92GGX6W"
      },
      "id": "lG_mx92GGX6W"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}